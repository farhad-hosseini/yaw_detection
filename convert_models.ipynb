{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_new = load_model(\"model_saved/Yaw_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:00<00:00,  6.60 passes/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 122/122 [00:00<00:00, 3388.82 ops/s]\n",
      "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 1750.13 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 56/56 [00:00<00:00, 189.19 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 8/8 [00:00<00:00, 258.06 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 194/194 [00:27<00:00,  7.18 ops/s]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = coremltools.convert(\"model_saved/Yaw_model.h5\")\n",
    "\n",
    "# coreml_model.visualize_spec()\n",
    "\n",
    "coreml_model.save(\"model_saved/Yaw_prediction.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_yolov5 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39multralytics/yolov5\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m , path\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39myolov5s.mlmodel\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m model_yolov5\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;31mTypeError\u001b[0m: load() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_yolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model_yolov5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\admin/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-5-2 Python-3.10.11 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24575MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\admin\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yolov5s.mlmodel for CoreML inference...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: 'yolov5s.mlmodel'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:49\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     model \u001b[39m=\u001b[39m DetectMultiBackend(path, device\u001b[39m=\u001b[39;49mdevice, fuse\u001b[39m=\u001b[39;49mautoshape)  \u001b[39m# detection model\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m autoshape:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:422\u001b[0m, in \u001b[0;36mDetectMultiBackend.__init__\u001b[1;34m(self, weights, device, dnn, data, fp16, fuse)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcoremltools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mct\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m     model \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mMLModel(w)\n\u001b[0;32m    423\u001b[0m \u001b[39melif\u001b[39;00m saved_model:  \u001b[39m# TF SavedModel\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\models\\model.py:340\u001b[0m, in \u001b[0;36mMLModel.__init__\u001b[1;34m(self, model, is_temp_package, mil_program, skip_model_load, compute_units, weights_dir)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_dir \u001b[39m=\u001b[39m _try_get_weights_dir_path(model)\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__proxy__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_framework_error \u001b[39m=\u001b[39m _get_proxy_and_spec(\n\u001b[0;32m    341\u001b[0m         model, compute_units, skip_model_load\u001b[39m=\u001b[39;49mskip_model_load,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    343\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, _Model_pb2\u001b[39m.\u001b[39mModel):\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\models\\model.py:132\u001b[0m, in \u001b[0;36m_get_proxy_and_spec\u001b[1;34m(filename, compute_units, skip_model_load)\u001b[0m\n\u001b[0;32m    131\u001b[0m filename \u001b[39m=\u001b[39m _os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(filename)\n\u001b[1;32m--> 132\u001b[0m specification \u001b[39m=\u001b[39m _load_spec(filename)\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m _MLModelProxy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_model_load:\n\u001b[0;32m    135\u001b[0m \n\u001b[0;32m    136\u001b[0m     \u001b[39m# check if the version is supported\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\models\\utils.py:225\u001b[0m, in \u001b[0;36mload_spec\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m    224\u001b[0m spec \u001b[39m=\u001b[39m _Model_pb2\u001b[39m.\u001b[39mModel()\n\u001b[1;32m--> 225\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(specfile, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    226\u001b[0m     spec\u001b[39m.\u001b[39mParseFromString(f\u001b[39m.\u001b[39mread())\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\admin\\\\Desktop\\\\car_pose_estimation\\\\3d\\\\yolov5s.mlmodel'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:60\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         model \u001b[39m=\u001b[39m attempt_load(path, device\u001b[39m=\u001b[39;49mdevice, fuse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)  \u001b[39m# arbitrary model\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py:79\u001b[0m, in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m weights \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(weights, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m [weights]:\n\u001b[1;32m---> 79\u001b[0m     ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(attempt_download(w), map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# load\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     ckpt \u001b[39m=\u001b[39m (ckpt\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mema\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m ckpt[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()  \u001b[39m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    272\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov5s.mlmodel'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39multralytics/yolov5\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcustom\u001b[39;49m\u001b[39m'\u001b[39;49m, path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39myolov5s.mlmodel\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\hub.py:558\u001b[0m, in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgithub\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    555\u001b[0m     repo_or_dir \u001b[39m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[39m\"\u001b[39m\u001b[39mload\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    556\u001b[0m                                        verbose\u001b[39m=\u001b[39mverbose, skip_validation\u001b[39m=\u001b[39mskip_validation)\n\u001b[1;32m--> 558\u001b[0m model \u001b[39m=\u001b[39m _load_local(repo_or_dir, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\hub.py:587\u001b[0m, in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m     hub_module \u001b[39m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[0;32m    586\u001b[0m     entry \u001b[39m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m--> 587\u001b[0m     model \u001b[39m=\u001b[39m entry(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:83\u001b[0m, in \u001b[0;36mcustom\u001b[1;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom\u001b[39m(path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath/to/model.pt\u001b[39m\u001b[39m'\u001b[39m, autoshape\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     82\u001b[0m     \u001b[39m# YOLOv5 custom or local model\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m _create(path, autoshape\u001b[39m=\u001b[39;49mautoshape, verbose\u001b[39m=\u001b[39;49m_verbose, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:78\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m help_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     77\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. Cache may be out of date, try `force_reload=True` or see \u001b[39m\u001b[39m{\u001b[39;00mhelp_url\u001b[39m}\u001b[39;00m\u001b[39m for help.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 78\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(s) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: [Errno 2] No such file or directory: 'yolov5s.mlmodel'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help."
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s.mlmodel') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to determine the type of the model, i.e. the source framework. Please provide the value of argument \"source\", from one of [\"tensorflow\", \"pytorch\", \"milinternal\"]. Note that model conversion requires the source package that generates the model. Please make sure you have the appropriate version of source package installed. E.g., if you're converting model originally trained with TensorFlow 1.14, make sure you have `tensorflow==1.14` installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcoremltools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mct\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Load the ONNX model coremltools.convert\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m onnx_model \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39myolov5s.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Convert the ONNX model to a Core ML model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m mlmodel \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mconvert(onnx_model)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:461\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[0;32m    459\u001b[0m _check_deployment_target(minimum_deployment_target)\n\u001b[0;32m    460\u001b[0m outputs_as_strings, outputs_as_tensor_or_image_types \u001b[39m=\u001b[39m _validate_outputs_argument(outputs)\n\u001b[1;32m--> 461\u001b[0m exact_source \u001b[39m=\u001b[39m _determine_source(model, source,\n\u001b[0;32m    462\u001b[0m                                  outputs_as_strings,\n\u001b[0;32m    463\u001b[0m                                  outputs_as_tensor_or_image_types,\n\u001b[0;32m    464\u001b[0m                                  outputs)\n\u001b[0;32m    465\u001b[0m exact_target \u001b[39m=\u001b[39m _determine_target(convert_to, minimum_deployment_target)\n\u001b[0;32m    466\u001b[0m _validate_conversion_arguments(model, exact_source, inputs, outputs_as_tensor_or_image_types,\n\u001b[0;32m    467\u001b[0m                                classifier_config, compute_precision,\n\u001b[0;32m    468\u001b[0m                                exact_target, minimum_deployment_target)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:822\u001b[0m, in \u001b[0;36m_determine_source\u001b[1;34m(model, source, output_names, outputs_as_tensor_or_image_types, output_argument_as_specified_by_user)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmilinternal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    813\u001b[0m msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    814\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUnable to determine the type of the model, i.e. the source framework. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease provide the value of argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, from one of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39myou have `tensorflow==1.14` installed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m )\n\u001b[1;32m--> 822\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to determine the type of the model, i.e. the source framework. Please provide the value of argument \"source\", from one of [\"tensorflow\", \"pytorch\", \"milinternal\"]. Note that model conversion requires the source package that generates the model. Please make sure you have the appropriate version of source package installed. E.g., if you're converting model originally trained with TensorFlow 1.14, make sure you have `tensorflow==1.14` installed."
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "# Load the ONNX model coremltools.convert\n",
    "onnx_model = ct.convert('yolov5s.pt')\n",
    "\n",
    "# Convert the ONNX model to a Core ML model\n",
    "mlmodel = ct.convert(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('my_mlmodel.mlmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolov5.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_yolov5.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:514: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
      "C:\\Users\\admin/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:64: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = ['image']\n",
    "output_names = ['output']\n",
    "\n",
    "# Export PyTorch model to ONNX\n",
    "torch.onnx.export(model_yolov5, torch.randn((1, 3, 640, 640)), 'yolov5s.onnx', export_params=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to determine the type of the model, i.e. the source framework. Please provide the value of argument \"source\", from one of [\"tensorflow\", \"pytorch\", \"milinternal\"]. Note that model conversion requires the source package that generates the model. Please make sure you have the appropriate version of source package installed. E.g., if you're converting model originally trained with TensorFlow 1.14, make sure you have `tensorflow==1.14` installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcoremltools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mct\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Load the ONNX model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# onnx_model = onnx.load('yolov5s.onnx')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[39m# Convert ONNX model to Core ML model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m mlmodel \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39myolov5s.onnx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Save the Core ML model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m mlmodel\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39myolov5s.mlmodel\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:461\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[0;32m    459\u001b[0m _check_deployment_target(minimum_deployment_target)\n\u001b[0;32m    460\u001b[0m outputs_as_strings, outputs_as_tensor_or_image_types \u001b[39m=\u001b[39m _validate_outputs_argument(outputs)\n\u001b[1;32m--> 461\u001b[0m exact_source \u001b[39m=\u001b[39m _determine_source(model, source,\n\u001b[0;32m    462\u001b[0m                                  outputs_as_strings,\n\u001b[0;32m    463\u001b[0m                                  outputs_as_tensor_or_image_types,\n\u001b[0;32m    464\u001b[0m                                  outputs)\n\u001b[0;32m    465\u001b[0m exact_target \u001b[39m=\u001b[39m _determine_target(convert_to, minimum_deployment_target)\n\u001b[0;32m    466\u001b[0m _validate_conversion_arguments(model, exact_source, inputs, outputs_as_tensor_or_image_types,\n\u001b[0;32m    467\u001b[0m                                classifier_config, compute_precision,\n\u001b[0;32m    468\u001b[0m                                exact_target, minimum_deployment_target)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:822\u001b[0m, in \u001b[0;36m_determine_source\u001b[1;34m(model, source, output_names, outputs_as_tensor_or_image_types, output_argument_as_specified_by_user)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmilinternal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    813\u001b[0m msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    814\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUnable to determine the type of the model, i.e. the source framework. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease provide the value of argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, from one of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39myou have `tensorflow==1.14` installed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m )\n\u001b[1;32m--> 822\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to determine the type of the model, i.e. the source framework. Please provide the value of argument \"source\", from one of [\"tensorflow\", \"pytorch\", \"milinternal\"]. Note that model conversion requires the source package that generates the model. Please make sure you have the appropriate version of source package installed. E.g., if you're converting model originally trained with TensorFlow 1.14, make sure you have `tensorflow==1.14` installed."
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "# Load the ONNX model\n",
    "# onnx_model = onnx.load('yolov5s.onnx')\n",
    "\n",
    "# Convert ONNX model to Core ML model\n",
    "mlmodel = ct.convert('yolov5s.onnx')\n",
    "\n",
    "# Save the Core ML model\n",
    "mlmodel.save('yolov5s.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# im = cv2.imread(\"sh/IMG_3695.jpg\")\n",
    "im =  torch.rand(1,700,700,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected argument for pytorch \"inputs\" not provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coremltools\u001b[39m.\u001b[39;49mconvert(model_yolov5 , source\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpytorch\u001b[39;49m\u001b[39m\"\u001b[39;49m )\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:466\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[0;32m    461\u001b[0m exact_source \u001b[39m=\u001b[39m _determine_source(model, source,\n\u001b[0;32m    462\u001b[0m                                  outputs_as_strings,\n\u001b[0;32m    463\u001b[0m                                  outputs_as_tensor_or_image_types,\n\u001b[0;32m    464\u001b[0m                                  outputs)\n\u001b[0;32m    465\u001b[0m exact_target \u001b[39m=\u001b[39m _determine_target(convert_to, minimum_deployment_target)\n\u001b[1;32m--> 466\u001b[0m _validate_conversion_arguments(model, exact_source, inputs, outputs_as_tensor_or_image_types,\n\u001b[0;32m    467\u001b[0m                                classifier_config, compute_precision,\n\u001b[0;32m    468\u001b[0m                                exact_target, minimum_deployment_target)\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m pass_pipeline \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m     pass_pipeline \u001b[39m=\u001b[39m PassPipeline()\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\coremltools\\converters\\_converters_entry.py:735\u001b[0m, in \u001b[0;36m_validate_conversion_arguments\u001b[1;34m(model, exact_source, inputs, outputs, classifier_config, compute_precision, convert_to, minimum_deployment_target)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[39melif\u001b[39;00m exact_source \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 735\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected argument for pytorch \u001b[39m\u001b[39m\"\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m not provided\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    737\u001b[0m     raise_if_duplicated(flat_inputs)\n\u001b[0;32m    738\u001b[0m     \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    739\u001b[0m         [\u001b[39misinstance\u001b[39m(_input, InputType) \u001b[39mfor\u001b[39;00m _input \u001b[39min\u001b[39;00m flat_inputs]\n\u001b[0;32m    740\u001b[0m     ):\n",
      "\u001b[1;31mValueError\u001b[0m: Expected argument for pytorch \"inputs\" not provided"
     ]
    }
   ],
   "source": [
    "coremltools.convert( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 6, 6], expected input[1, 700, 700, 3] to have 3 channels, but got 700 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m traced_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model_yolov5 , im)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\jit\\_trace.py:794\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mexample_kwarg_inputs should be a dict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 794\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    795\u001b[0m         func,\n\u001b[0;32m    796\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[0;32m    797\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m         check_trace,\n\u001b[0;32m    799\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[0;32m    800\u001b[0m         check_tolerance,\n\u001b[0;32m    801\u001b[0m         strict,\n\u001b[0;32m    802\u001b[0m         _force_outplace,\n\u001b[0;32m    803\u001b[0m         _module_class,\n\u001b[0;32m    804\u001b[0m         example_inputs_is_kwarg\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(example_kwarg_inputs, \u001b[39mdict\u001b[39;49m),\n\u001b[0;32m    805\u001b[0m         _store_inputs\u001b[39m=\u001b[39;49m_store_inputs\n\u001b[0;32m    806\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    808\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    809\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[0;32m    810\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m ):\n\u001b[0;32m    812\u001b[0m     \u001b[39mif\u001b[39;00m example_inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\jit\\_trace.py:1056\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m-> 1056\u001b[0m     module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[0;32m   1057\u001b[0m         method_name,\n\u001b[0;32m   1058\u001b[0m         func,\n\u001b[0;32m   1059\u001b[0m         example_inputs,\n\u001b[0;32m   1060\u001b[0m         var_lookup_fn,\n\u001b[0;32m   1061\u001b[0m         strict,\n\u001b[0;32m   1062\u001b[0m         _force_outplace,\n\u001b[0;32m   1063\u001b[0m         argument_names,\n\u001b[0;32m   1064\u001b[0m         _store_inputs\n\u001b[0;32m   1065\u001b[0m     )\n\u001b[0;32m   1067\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[0;32m   1069\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:675\u001b[0m, in \u001b[0;36mAutoShape.forward\u001b[1;34m(self, ims, size, augment, profile)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ims, torch\u001b[39m.\u001b[39mTensor):  \u001b[39m# torch\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[39mwith\u001b[39;00m amp\u001b[39m.\u001b[39mautocast(autocast):\n\u001b[1;32m--> 675\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(ims\u001b[39m.\u001b[39;49mto(p\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mtype_as(p), augment\u001b[39m=\u001b[39;49maugment)  \u001b[39m# inference\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[39m# Pre-process\u001b[39;00m\n\u001b[0;32m    678\u001b[0m n, ims \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(ims), \u001b[39mlist\u001b[39m(ims)) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ims, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39melse\u001b[39;00m (\u001b[39m1\u001b[39m, [ims])  \u001b[39m# number, list of images\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:514\u001b[0m, in \u001b[0;36mDetectMultiBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    511\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[0;32m    515\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:209\u001b[0m, in \u001b[0;36mDetectionModel.forward\u001b[1;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[0;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_augment(x)  \u001b[39m# augmented inference, None\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_once(x, profile, visualize)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:121\u001b[0m, in \u001b[0;36mBaseModel._forward_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[0;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 121\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[0;32m    122\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:59\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\gputest\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 6, 6], expected input[1, 700, 700, 3] to have 3 channels, but got 700 channels instead"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model_yolov5 , im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
